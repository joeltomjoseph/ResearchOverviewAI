import ollama
import pydantic

''' Pydantic model for the metadata to be generated by the Ollama API
    https://ollama.com/blog/structured-outputs '''
class Metadata(pydantic.BaseModel):
    title: str
    summary: str
    # authors: list[str]
    datasets: list[str]
    metrics: list[str]
    methods: list[str]
    applications: list[str]
    limitations: list[str]
    areasOfImprovement: list[str]

def getAvailableModels() -> list:
    ''' Gets the list of available model names from the Ollama API '''
    try:
        return [model.model for model in ollama.list().models]
    except:
        return ["llama3.1:8b"]  # Fallback TODO: change to error?

def generateMetadata(text: str, modelName: str) -> str:
    ''' Generates metadata from the given text using the specified model '''
    try:
        response = ollama.chat(
            model = modelName,
            format=Metadata.model_json_schema(), # Format the response as a JSON schema from the Metadata model
            # options={"num_ctx": 4096}, # Increase the context size
            messages = [{
                "role": "user",
                "content": f"""PROMPT: Generate metadata for the following paper in JSON format. Use exact extracts/sections/titles/names where possible. Validate the output for accuracy and completeness.

                PAPER CONTENT: {text}..."""
            }]
        )
        return response.message.content
    except Exception as e:
        return {"error": f"Metadata generation failed: {str(e)}"}

def generateEmbedding(text: str, modelName: str) -> list[list[float]]:
    ''' Generates a vector embedding for the given text using the specified model '''
    try:
        response = ollama.embed(model=modelName, input=text)
        return response.embeddings
    except Exception as e:
        raise Exception(f"Embedding generation failed: {str(e)}")

if __name__ == "__main__": # Test the functions
    import arxiv
    import extractText

    print("Available Models: ", getAvailableModels()) # Find all available models

    client = arxiv.Client() # Create client
    search = arxiv.Search(id_list=["2310.11453"], max_results=1) # Search for the BitNet paper to test
    paper = client.results(search).__next__() # Get the paper

    path = paper.download_pdf("data/papers") # Download the paper
    text = extractText.extractText(path) # Extract text from the paper

    # print(text)
    print(generateMetadata(text, 'deepseek-r1:8b'))
    # print(generateEmbedding(text, "nomic-embed-text:latest"))